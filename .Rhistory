library(here)
# Read in the data
load_tree = read.csv(here('load_tree.csv'))
library(here)
# Read in the data
load_tree = read.csv(here('load_tree.csv'))
###
# Bagging and random forests
###
library(tidyverse)
library(rpart)
library(rpart.plot)
library(rsample)
library(randomForest)
library(lubridate)
library(modelr)
library(here)
# Read in the data
load_tree = read.csv(here('load_tree.csv'))
###
library(tidyverse)
library(rpart)
library(rpart.plot)
library(rsample)
library(randomForest)
library(lubridate)
library(modelr)
library(here)
## Run this first for packages and working directory
knitr::opts_knit$set(root.dir = 'G:/My Drive/Pitt/24 Spring/Machine Learning')
# Package names
packages <- c(
"grf",
"ggplot2"
)
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
data <- read.csv("R Scripts/carvalho2016.csv")
# As outcomes we'll look at the number of correct answers.
Y <- data$outcome.num.correct.ans
# W is treatment
W <- data$treatment
# X is covariate matrix
X <- data[-(1:4)]
# Regression forest creates an estimate of the conditional mean mu(x) = E[Y | X = x]
Y.forest <- regression_forest(
X = X,
Y = Y,
num.trees = 2000,         # default 2000
sample.fraction = 0.5,    # Fraction of the data used to build each tree, default is .5
honesty = TRUE            # See note about honesty below
)
## About Honest Trees:
# Honest trees are designed to reduce bias in predictions. In a classic RF, a single subsample is used both to choose the tree split and for the leaf nodes making the predictions. Honest forests split the subsample and use one half for splitting and the other half for the nodes. This helps prevent overfitting, but may have performance suffer if a lack of data creates too many empty leaves.
Y.hat <- predict(Y.forest)$predictions
varimp.Y <- variable_importance(Y.forest)
# Keep the top 10 variables for CATE estimation
keep <- colnames(X)[order(varimp.Y, decreasing = TRUE)[1:10]]
keep
X.cf <- X[, keep]   # keep just the important covariates
W.hat <- 0.5        # estimated propensity of being treated (here .5 because of the RCT design, but this would need to change in other designs)
# Set aside the first half of the data for training and the second for evaluation.
# (Note that the results may change depending on which samples we hold out for training/evaluation)
train <- 1:(nrow(X.cf) / 2)
# Causal Forest is used to estimate the conditional average treatment effect tau(x)
train.forest <- causal_forest(
X = X.cf[train, ],
Y = Y[train],
W = W[train],
Y.hat = Y.hat[train],
W.hat = W.hat,
num.trees = 2000,           # default
clusters = NULL,            # default
honesty = TRUE,             # default
# a number of tuning parameters are omitted that may be necessary for your specifications
)
tau.hat.eval <- predict(train.forest, X.cf[-train, ])$predictions
eval.forest <- causal_forest(
X = X.cf[-train, ],
Y = Y[-train],
W = W[-train],
Y.hat = Y.hat[-train],
W.hat = W.hat
)
# Notice that we can't rule out no effect of this treatment on average!
average_treatment_effect(
eval.forest,              # use the trained forest
)
varimp <- variable_importance(eval.forest)
ranked.vars <- order(varimp, decreasing = TRUE)
colnames(X.cf)[ranked.vars[1:5]]
#  The Rank-Weighted Average Treatment Effect (RATE) available in the function rank_average_treatment_effect can be used to evaluate how good treatment prioritization rules (such as conditional average treatment effect estimates) are at distinguishing subpopulations with different treatment effects, or whether there is any notable heterogeneity present.
rate.cate <- rank_average_treatment_effect(
forest = eval.forest,
priorities = list(cate = -1 *tau.hat.eval),   # See note about priorities below
target = "AUTOC",                             # The type of RATE estimate, AUTOC better here
R = 200                                       # The number of bootstraps for SEs, default
)
plot(rate.cate, ylab = "Number of correct answers", main = "TOC: By most negative CATEs")
rate.age <- rank_average_treatment_effect(
eval.forest,
list(age = X[-train, "age"])
)
plot(rate.age, ylab = "Number of correct answers", main = "TOC: By decreasing age")
tau.hat.eval
last()
list()
?list
?list
list(cate = -1 *tau.hat.eval)
#  The Rank-Weighted Average Treatment Effect (RATE) available in the function rank_average_treatment_effect can be used to evaluate how good treatment prioritization rules (such as conditional average treatment effect estimates) are at distinguishing subpopulations with different treatment effects, or whether there is any notable heterogeneity present.
rate.cate <- rank_average_treatment_effect(
forest = eval.forest,
priorities = list(cate = 1 *tau.hat.eval),   # See note about priorities below
target = "AUTOC",                             # The type of RATE estimate, AUTOC better here
R = 200                                       # The number of bootstraps for SEs, default
)
# Priorities: this assigns scores (here based on CATE)
rate.age <- rank_average_treatment_effect(
eval.forest,
list(age = X[-train, "age"])
)
# RATE has a very appealing visual component that allows us to detect heterogeneity as we vary the treated fraction
plot(rate.cate, ylab = "Number of correct answers", main = "TOC: By most negative CATEs")
plot(rate.age, ylab = "Number of correct answers", main = "TOC: By decreasing age")
#  The Rank-Weighted Average Treatment Effect (RATE) available in the function rank_average_treatment_effect can be used to evaluate how good treatment prioritization rules (such as conditional average treatment effect estimates) are at distinguishing subpopulations with different treatment effects, or whether there is any notable heterogeneity present.
rate.cate <- rank_average_treatment_effect(
forest = eval.forest,
priorities = list(cate = -1 *tau.hat.eval),   # See note about priorities below
target = "AUTOC",                             # The type of RATE estimate, AUTOC better here
R = 200                                       # The number of bootstraps for SEs, default
)
# Priorities: this assigns scores (here based on CATE) of treatment prioritization. They make it negative in this case for interpretability; that is, to highlight the effect of being more affected by poverty / before payday on negative result of test scores.
rate.age <- rank_average_treatment_effect(
eval.forest,
list(age = X[-train, "age"])
)
# RATE has a very appealing visual component that allows us to detect heterogeneity as we vary the treated fraction
plot(rate.cate, ylab = "Number of correct answers", main = "TOC: By most negative CATEs")
plot(rate.age, ylab = "Number of correct answers", main = "TOC: By decreasing age")
?variable_importance
varimp.Y
knitr::opts_chunk$set(echo = TRUE)
# load data
studysample <- read.csv(here("data/studysampleclean.csv"))
knitr::opts_chunk$set(echo = TRUE)
# load data
studysample <- read.csv(here("data/studysampleclean.csv"))
##############################################
# Author: Brandon Williams
# Date: 10/29/2024
# Description:
#   Simply run this file first before using
#   other R scripts
#
##############################################
# set wd to this file path of this source file in order to successfully execute 'here' package. For example:
# setwd("C:/Users/BJW95/Documents/GitHub/het_treat_effects")
setwd("C:/Users/bjwil/OneDrive/Documents/GitHub/het_treat_effects")
# installs the librarian package if you don't have it
if (!("librarian" %in% rownames(utils::installed.packages()))) {
utils::install.packages("librarian")
}
# put all of the packages that you import here
librarian::shelf(
cran_repo = "https://cran.microsoft.com/", # Dallas, TX
ask = FALSE,
stats,
here,
tidyverse,
foreign,
haven,
ranger,
glmnet,
e1071,
xgboost,
devtools,
broom,               # tidy tibbles for lm
sandwich,            # robust standard errors
lmtest,
openxlsx,
car
)
# tell here where we are so we can use it elsewhere
here::i_am("R/include.R")
knitr::opts_chunk$set(echo = TRUE)
# load data
studysample <- read.csv(here("data/studysampleclean.csv"))
# Define global variable list
varlist <- c("presence", "evmar05v3", "evpreg05v3", "evpregunmar05v3", "evunpregmar05v3", "dropout05v3",
"dropout07v2", "evmar07v2", "evpreg07v2", "evpregunmar07v2", "evunpregmar07v2")
treatlist <- c("Uonly", "Honly","UH")
controllist <- c("yrbirth_all", "yrbirth_missing", "date05v3", "date07v2", "schsize", "stratum")
#### Machine Learning ####
# newest version of GenericML not yet on CRAN so install from here (instead of include.R)
# devtools::install_github("mwelz/GenericML")
library("GenericML")
# pre-process
sampleselect <- studysample %>%
select(all_of(varlist),                   # select relevant columns
all_of(controllist),
all_of(treatlist)) %>%
filter(complete.cases(.))                 # remove NAs
samplematrix <- data.matrix(sampleselect)                         # we need it in matrix form
Uonly <- sampleselect$Uonly                                       # We need D and Y in vector form
Honly <- sampleselect$Honly
dropout05v3 <- sampleselect$dropout05v3
# specify learners
learners <-
c("random_forest",                                              # Random Forest
"mlr3::lrn('cv_glmnet', s = 'lambda.min', alpha = 0.5)",      # Elastic Net Regularization on generalized linear model
"mlr3::lrn('svm')",                                           # Support vector machine
"mlr3::lrn('xgboost')")                                       # Gradient Boost
# Parameterize
seed <- 1833
cutoffs <- c(0.2, 0.4, 0.6, 0.8)
X1 <- setup_X1(funs_Z = c("B", "S")                    # include BCA and CATE controls
# , fixed_effects =
)
vcov <- setup_vcov(
# estimator = "vcovCL"              # I was not able to get this to take the vcovCL argument
# , arguments = list(cluster = )    # what are we meant to cluster on?
)
lps <- c("constant")
X1 <- setup_X1(funs_Z = c("B", "S"))
num_splits <- 100L
sig_level <- 0.05
parallel <- TRUE
num_cores <- 6L
genML <- GenericML(
Z = samplematrix,                         # matrix
D = Honly,                                # treatment assignment
Y = dropout05v3,                          # outcome response variable
learners_GenericML = learners,            # learners
learner_propensity_score = lps,           # = 0.5 (RCT)
num_splits = num_splits,                  # number splits, L is useful for specifying integer and therefore optimizing memory
quantile_cutoffs = cutoffs,               # grouping
significance_level = sig_level,           # significance level
X1_BLP = X1, X1_GATES = X1,               # regression setup
vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
parallel = parallel,                      # parallelization
# num_cores = num_cores,
seed = seed                               # RNG seed
)
# BLP
results_BLP <- get_BLP(genML, plot = TRUE)
results_BLP       # print method
plot(results_BLP) # plot method
# BLP
results_BLP <- get_BLP(genML, plot = TRUE)
results_BLP       # print method
plot(results_BLP) # plot method
# GATES
results_GATES <- get_GATES(genML, plot = TRUE)
results_GATES
plot(results_GATES)
# CLAN
# results_CLAN <- get_CLAN(genML, variable = "head_age_bl", plot = TRUE)
# results_CLAN
# plot(results_CLAN)
?GenericML
y_variable <- varlist[6]
treatment <- treatlist[1]
sampleselect <- studysample %>%
mutate(control = case_when(
Utreat.y == 0 & HIVtreat.y == 0 ~ 1,
TRUE ~ 0
))
sampleselect <- sampleselect %>%
filter(!!sym(treatment) == 1 | control == 1) %>%
select(all_of(varlist),                   # select relevant columns
all_of(controllist),
all_of(treatlist),
) %>%
filter(complete.cases(.))                 # remove NA
knitr::opts_chunk$set(echo = TRUE)
# load data
studysample <- read.csv(here("data/studysampleclean.csv"))
# Define global variable list
varlist <- c("presence", "evmar05v3", "evpreg05v3", "evpregunmar05v3", "evunpregmar05v3", "dropout05v3",
"dropout07v2", "evmar07v2", "evpreg07v2", "evpregunmar07v2", "evunpregmar07v2")
treatlist <- c("Uonly", "Honly","UH")
controllist <- c("yrbirth_all", "yrbirth_missing", "date05v3", "date07v2", "schsize", "stratum")
#### Machine Learning ####
# newest version of GenericML not yet on CRAN so install from here (instead of include.R)
# devtools::install_github("mwelz/GenericML")
library("GenericML")
# pre-process
# sampleselect <- studysample %>%
#   select(all_of(varlist),                   # select relevant columns
#          all_of(controllist),
#          all_of(treatlist)) %>%
#   filter(complete.cases(.))                 # remove NAs
y_variable <- varlist[6]
treatment <- treatlist[1]
sampleselect <- studysample %>%
mutate(control = case_when(
Utreat.y == 0 & HIVtreat.y == 0 ~ 1,
TRUE ~ 0
))
sampleselect <- sampleselect %>%
filter(!!sym(treatment) == 1 | control == 1) %>%
select(all_of(varlist),                   # select relevant columns
all_of(controllist),
all_of(treatlist),
) %>%
filter(complete.cases(.))                 # remove NA
samplematrix <- data.matrix(sampleselect)                         # we need it in matrix form
Uonly <- sampleselect$Uonly                                       # We need D and Y in vector form
Honly <- sampleselect$Honly
dropout05v3 <- sampleselect$dropout05v3
# specify learners
learners <-
c("random_forest",                                              # Random Forest
"mlr3::lrn('cv_glmnet', s = 'lambda.min', alpha = 0.5)",      # Elastic Net Regularization on generalized linear model
"mlr3::lrn('svm')",                                           # Support vector machine
"mlr3::lrn('xgboost')")                                       # Gradient Boost
# Parameterize
seed <- 1833
cutoffs <- c(0.2, 0.4, 0.6, 0.8)
X1 <- setup_X1(funs_Z = c("B", "S")                    # include BCA and CATE controls
# , fixed_effects =
)
vcov <- setup_vcov(
# estimator = "vcovCL"              # I was not able to get this to take the vcovCL argument
# , arguments = list(cluster = )    # what are we meant to cluster on?
)
lps <- c("constant")
# X1 <- setup_X1(funs_Z = c("B", "S"))
num_splits <- 100L
sig_level <- 0.05
parallel <- TRUE
num_cores <- 6L
genML <- GenericML(
Z = samplematrix,                         # matrix
D = Uonly,                                # treatment assignment
Y = dropout05v3,                          # outcome response variable
learners_GenericML = learners,            # learners
learner_propensity_score = lps,           # = 0.5 (RCT)
num_splits = num_splits,                  # number splits, L is useful for specifying integer and therefore optimizing memory
quantile_cutoffs = cutoffs,               # grouping
significance_level = sig_level,           # significance level
X1_BLP = X1, X1_GATES = X1,               # regression setup
vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
parallel = parallel,                      # parallelization
# num_cores = num_cores,
seed = seed                               # RNG seed
)
# BLP
results_BLP <- get_BLP(genML, plot = TRUE)
results_BLP       # print method
plot(results_BLP) # plot method
# GATES
results_GATES <- get_GATES(genML, plot = TRUE)
results_GATES
plot(results_GATES)
# CLAN
# results_CLAN <- get_CLAN(genML, variable = "head_age_bl", plot = TRUE)
# results_CLAN
# plot(results_CLAN)
# best learners
get_best(genML)
yrbirth_all <- as.numeric(factor(sampleselect$yrbirth_all))
X1 <- setup_X1(funs_Z = c("B", "S")                    # include BCA and CATE controls
, fixed_effects = yrbirth_all
)
genML <- GenericML(
Z = samplematrix,                         # matrix
D = Uonly,                                # treatment assignment
Y = dropout05v3,                          # outcome response variable
learners_GenericML = learners,            # learners
learner_propensity_score = lps,           # = 0.5 (RCT)
num_splits = num_splits,                  # number splits, L is useful for specifying integer and therefore optimizing memory
quantile_cutoffs = cutoffs,               # grouping
significance_level = sig_level,           # significance level
X1_BLP = X1, X1_GATES = X1,               # regression setup
vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
parallel = parallel,                      # parallelization
# num_cores = num_cores,
seed = seed                               # RNG seed
)
genML <- GenericML(
Z = samplematrix,                         # matrix
D = Uonly,                                # treatment assignment
Y = dropout05v3,                          # outcome response variable
learners_GenericML = learners,            # learners
learner_propensity_score = lps,           # = 0.5 (RCT)
num_splits = num_splits,                  # number splits, L is useful for specifying integer and therefore optimizing memory
quantile_cutoffs = cutoffs,               # grouping
significance_level = sig_level,           # significance level
X1_BLP = X1, X1_GATES = X1,               # regression setup
vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
parallel = parallel,                      # parallelization
# num_cores = num_cores,
seed = seed                               # RNG seed
)
# BLP
results_BLP <- get_BLP(genML, plot = TRUE)
results_BLP       # print method
plot(results_BLP) # plot method
# GATES
results_GATES <- get_GATES(genML, plot = TRUE)
results_GATES
plot(results_GATES)
# CLAN
# results_CLAN <- get_CLAN(genML, variable = "head_age_bl", plot = TRUE)
# results_CLAN
# plot(results_CLAN)
sampleselect <- sampleselect %>%
filter(!!sym(treatment) == 1 | control == 1) %>%
select(all_of(varlist),                   # select relevant columns
all_of(controllist),
all_of(treatlist),
schoolid
) %>%
filter(complete.cases(.))                 # remove NA
knitr::opts_chunk$set(echo = TRUE)
# load data
studysample <- read.csv(here("data/studysampleclean.csv"))
# Define global variable list
varlist <- c("presence", "evmar05v3", "evpreg05v3", "evpregunmar05v3", "evunpregmar05v3", "dropout05v3",
"dropout07v2", "evmar07v2", "evpreg07v2", "evpregunmar07v2", "evunpregmar07v2")
treatlist <- c("Uonly", "Honly","UH")
controllist <- c("yrbirth_all", "yrbirth_missing", "date05v3", "date07v2", "schsize", "stratum")
#### Machine Learning ####
# newest version of GenericML not yet on CRAN so install from here (instead of include.R)
# devtools::install_github("mwelz/GenericML")
library("GenericML")
# pre-process
# sampleselect <- studysample %>%
#   select(all_of(varlist),                   # select relevant columns
#          all_of(controllist),
#          all_of(treatlist)) %>%
#   filter(complete.cases(.))                 # remove NAs
y_variable <- varlist[6]
treatment <- treatlist[1]
sampleselect <- studysample %>%
mutate(control = case_when(
Utreat.y == 0 & HIVtreat.y == 0 ~ 1,
TRUE ~ 0
))
sampleselect <- sampleselect %>%
filter(!!sym(treatment) == 1 | control == 1) %>%
select(all_of(varlist),                   # select relevant columns
all_of(controllist),
all_of(treatlist),
schoolid
) %>%
filter(complete.cases(.))                 # remove NA
samplematrix <- data.matrix(sampleselect)                         # we need it in matrix form
Uonly <- sampleselect$Uonly                                       # We need D and Y in vector form
Honly <- sampleselect$Honly
dropout05v3 <- sampleselect$dropout05v3
yrbirth_all <- as.numeric(factor(sampleselect$yrbirth_all))
# specify learners
learners <-
c("random_forest",                                              # Random Forest
"mlr3::lrn('cv_glmnet', s = 'lambda.min', alpha = 0.5)",      # Elastic Net Regularization on generalized linear model
"mlr3::lrn('svm')",                                           # Support vector machine
"mlr3::lrn('xgboost')")                                       # Gradient Boost
# Parameterize
seed <- 1833
cutoffs <- c(0.2, 0.4, 0.6, 0.8)
X1 <- setup_X1(funs_Z = c("B", "S")                    # include BCA and CATE controls
, fixed_effects = yrbirth_all
)
vcov <- setup_vcov(
# estimator = "vcovCL"              # I was not able to get this to take the vcovCL argument
, arguments = list(cluster = sampleselect$schoolid)    # what are we meant to cluster on?
)
lps <- c("constant")
# X1 <- setup_X1(funs_Z = c("B", "S"))
num_splits <- 100L
sig_level <- 0.05
parallel <- TRUE
num_cores <- 6L
vcov <- setup_vcov(
# estimator = "vcovCL"              # I was not able to get this to take the vcovCL argument
arguments = list(cluster = sampleselect$schoolid)    # what are we meant to cluster on?
)
genML <- GenericML(
Z = samplematrix,                         # matrix
D = Uonly,                                # treatment assignment
Y = dropout05v3,                          # outcome response variable
learners_GenericML = learners,            # learners
learner_propensity_score = lps,           # = 0.5 (RCT)
num_splits = num_splits,                  # number splits, L is useful for specifying integer and therefore optimizing memory
quantile_cutoffs = cutoffs,               # grouping
significance_level = sig_level,           # significance level
X1_BLP = X1, X1_GATES = X1,               # regression setup
vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
parallel = parallel,                      # parallelization
# num_cores = num_cores,
seed = seed                               # RNG seed
)
# BLP
results_BLP <- get_BLP(genML, plot = TRUE)
results_BLP       # print method
plot(results_BLP) # plot method
# GATES
results_GATES <- get_GATES(genML, plot = TRUE)
results_GATES
plot(results_GATES)
# CLAN
results_CLAN <- get_CLAN(genML, variable = "schsize", plot = TRUE)
results_CLAN
plot(results_CLAN)
